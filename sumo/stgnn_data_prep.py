import sumolib
import pandas as pd
import numpy as np
import xml.etree.ElementTree as ET

NET_FILE = 'sumo/krakow_traffic.net.xml'
# The output file generated by the <e2Collector> in edge_data.add.xml
EDGE_FEATURES_FILE = 'sumo/edge_features.xml' 
OUTPUT_ADJ_MATRIX = 'sumo/adj_matrix.npy'
OUTPUT_FEATURES_CSV = 'sumo/time_series_features.csv'


def create_adjacency_matrix(net_file):
    """
    Builds the adjacency matrix (A) based on physical connectivity between edges.
    """
    print(f"Loading network from {net_file}...")
    net = sumolib.net.readNet(net_file)
    
    # 1. Get all relevant edge IDs and map them to matrix indices
    # Filter out internal, entry, or exit edges (if not needed for deep learning)
    edges = [e for e in net.getEdges() if not e.isSpecial()]
    edge_ids = [e.getID() for e in edges]
    id_to_index = {edge_id: i for i, edge_id in enumerate(edge_ids)}
    N = len(edge_ids)
    
    # 2. Initialize the adjacency matrix
    adj_matrix = np.zeros((N, N), dtype=int)
    
    # 3. Populate the matrix based on connections (links)
    for i, edge in enumerate(edges):
        # Get all outgoing edges directly
        outgoing_edges = edge.getOutgoing()
        
        for to_edge in outgoing_edges:
            # Check if the destination edge is in our list and map it
            if to_edge.getID() in id_to_index:
                j = id_to_index[to_edge.getID()]
                adj_matrix[i, j] = 1
    
    # Optional: Add self-loops (adj_matrix = A + I), common in GNNs
    # np.fill_diagonal(adj_matrix, 1) 
    
    print(f"Adjacency matrix created: {N} x {N}.")
    np.save(OUTPUT_ADJ_MATRIX, adj_matrix)
    
    return edge_ids, adj_matrix


def process_edge_features(edge_features_file, edge_ids):
    """
    Reads the SUMO edge features XML and organizes them into a time-series DataFrame.
    """
    print(f"Processing edge features from {edge_features_file}...")
    
    tree = ET.parse(edge_features_file)
    root = tree.getroot()
    
    # List to hold the flattened time-series data
    data_records = []
    
    for interval in root.findall('interval'):
        time_step = float(interval.get('begin'))
        
        # Dictionary to store features for all edges at this timestep
        step_data = {'time': time_step}
        
        # Initialize all edges to a default value (e.g., -1 or 0 for speed/flow)
        for edge_id in edge_ids:
            step_data[f'{edge_id}_meanSpeed'] = 0.0
            step_data[f'{edge_id}_flow'] = 0.0 
        
        for edge in interval.findall('edge'):
            edge_id = edge.get('id')
            
            # Only process if the edge is one of our primary road segments
            if edge_id in edge_ids:
                step_data[f'{edge_id}_meanSpeed'] = float(edge.get('speed', 0.0))
                # Count/Flow is often stored as 'nVehicles' or derived from 'flow'
                step_data[f'{edge_id}_flow'] = float(edge.get('flow', 0.0))

        data_records.append(step_data)

    if not data_records:
        print("Warning: No interval data found in the XML file.")
        return None

    # Convert the list of dictionaries to a Pandas DataFrame
    df = pd.DataFrame(data_records)
    df.set_index('time', inplace=True)
    
    # Ensure all time steps have all features (edges)
    # The final structure should be T rows x (N * F) columns
    
    df.to_csv(OUTPUT_FEATURES_CSV)
    print(f"Time-series features saved to {OUTPUT_FEATURES_CSV}.")
    print(f"Features shape: {df.shape}")
    
    return df


if __name__ == "__main__":
    
    edge_list, A = create_adjacency_matrix(NET_FILE)
    
    # NOTE: You must have run a SUMO simulation previously to generate 'edge_features.xml'
    X_df = process_edge_features(EDGE_FEATURES_FILE, edge_list)

    if X_df is not None:
        
        N = len(edge_list)
        T = len(X_df)
        F = 2 # Assuming meanSpeed and flow

        feature_columns = sorted([col for col in X_df.columns if '_meanSpeed' in col or '_flow' in col])
        
        ordered_cols = []
        for edge_id in edge_list:
            ordered_cols.append(f'{edge_id}_meanSpeed')
            ordered_cols.append(f'{edge_id}_flow')

        X_tensor = X_df[ordered_cols].values.reshape(T, N, F)
        
        print(f"\nSTGNN-ready Tensor shape (T x N x F): {X_tensor.shape}")
        print("Data is now ready for STGNN model input (Tensor X and Matrix A).")